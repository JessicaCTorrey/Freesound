import numpy as np

def dataset_maker(audio_path, classifications_path):
    """
    Function that generates a dataset (dict) that organizes all the relevant info for the project.

    inputs: 
        audio_path (str): path for all the audios in the dataset
        classifications_paths (str): path for the csv with the classifications
    outputs:
        dataset (dict): dictionary with the following structure
            keys  = number id of the audio
            items = dictionary of tracks with the following structure
                keys = audio_path (str), features (dict), class (str)  

    For example, once this function is run, one should be able to run codes like this

    DATASET = dataset_maker(audio_path, classifications_path)
    track_example = DATASET["1234"]
    print(track_example["audio_path"])
        blabla/blabla/1234.wav
    print(track_example["features"])
        dict[] <- this dictionary should be empty so far
    print(track_example["class"])
        "Insult in spanish female to male"       
    
    Note: all of this is just to make a dictionary that will hold all the info of your dataset the feature computation comes in the next part.
    """
    dataset = {}
    # read the csv containing the classifications
    # find each audio and save it to the dictionary doing something like this:
    # example: you found the audio blabla/blabla/1234.wav, so you will want to save its info to dataset by
    # dataset["1234"] ={"audio_path":"blabla/blabla/1234.wav",
    #                   "features"  : {},
    #                   "class"     : "insult in spanish female to male"}
    return dataset

def features_extractor(dataset):
    """
    Function that takes a dataset (dict) and add the features.

    inputs:
        dataset (dict): dataset that was generated using the dataset_maker
    outputs:
        dataset (dict): dataset identical to the inputed but with features computed

    Note: Remember to compute more than one aggregation! The names of the first moments are: mean, sd, skew and kurtosis.
    """

    # Initialize all the features extractors as in the essentia lab (remember depending on the algorithm you might need to read the file with different sr and mono/stereo specs)
    # For each track in the dataset compute their features and save them like this:
    # dataset["1234"]["feaftures"]["MFCC_1"] = 14
    # In case it is necessary I'll attach my essentia lab to this file.

    return dataset 

def class_to_one_hot(classification):
    """
    Function used to transform a classification (str) into a vector (np.array).

    inputs:
        class (str): classification as a string
    outputs:
        one-hot (np.array): numpy array that is a one-hot encoded vector. It must be a different type for each classification possible!
    """

    return 0

def dataset_to_numpy(dataset):
    """
    Function that rearrange the dataset into a matrix that can be used to train models.

    inputs:
        dataset (dict): dataset that eas generated using dataset_maker and that already has its features computed
    outputs:
        X (np.array 2d): matrix that has all the features ORDERED for all the samples of the dataset. Each row should be a sample. Each column a feature.
        y (np.array 2d): matrix that has all the classifications of all the samples of the dataset. Each row is the class of a different sample and is encoded as a one-hot vector.
    """
    X = np.array([])
    y = np.array([])
    # Read tracks one by one. Then make a numpy array containing all the features. Then concatenate all these vectors. This will give you X.
    # Read tracks one by one. Then make a numpy array containing all the classifications using the class_to_one_hot function. Then concatenate all these vectors. This will give you y.

    return X, y

def dim_red_simple(X, feat_1, feat_2):
    """
    Function that apply dimensionality reduction by simply removing a bunch of features.

    inputs:
        X (np.array 2d): matrix generated by dataset_to_numpy
        feat_1 (int): number corresponding to feature 1 to be used
        feat_2 (int): number corresponding to feature 2 to be used
    outputs:
        X_red (np.array 2d): matrix that has the same amount of rows that X (same amount of samples), but now it only has two columns corresponding to the feat_1 and feat_2 
    """
    return X

def dim_red_pca(X):
    """
    Function that apply dimensionality reduction using the PCA algorithm.

    inputs:
        X (np.array 2d): matrix generated by dataset_to_numpy
    outputs:
        X_red (np.array 2d): matrix that has the same amount of rows that X (same amount of samples), but now it only has two columns corresponding to the reduction.

    Example of PCA using scikitlearn (machine learning library super easy to use):
        import numpy as np
        from sklearn.decomposition import PCA
        X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
        pca = PCA(n_components=2)
        pca.fit(X)
        PCA(n_components=2)
        print(pca.explained_variance_ratio_)
        [0.9924... 0.0075...]
        print(pca.singular_values_)
        [6.30061... 0.54980...]
    """
    X_red = X
    return X_red

def cluster_score(X_red,y):
    """
    Function that uses a reduced version of X (only dim=2 in the latent space) to train a model to see if the classification works. 
    Many model can be used for this task, several examples of this can be found in my ATSMC assignment 3 attached to this file.
    This function should separate X_red and y into train and validation sets beforehand. I recommend a ratio of 80/20.

    inputs:
        X_red (np.array 2d): matrix of latent space data
        y (np.array 2d): matrix of classifications
    outputs:
        score (float): score of the classifier trained on the training set when applied in the validation set.

    Note: I recommend running this more than once and compute average of scores for stability.
    """
    score = 0
    return score

